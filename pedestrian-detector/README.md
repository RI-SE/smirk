# Pedestrian Detector

## Installation
Using poetry on linux:

```
$ poetry install
```

A temporary workaround on Windows/pip is:

```
$ pip install -r requirements.txt
$ pip install tf-models/research/
```

## Data
Training data should be in [TFRecord](https://www.tensorflow.org/tutorials/load_data/tfrecord) format with an accompanying label map, as described [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md).

These should be placed in the data folder:

```
data
├── label_map.txt
├── test.tfrecord
└── train.tfrecord
```

The TFRecord files can also be generated from a labeled image dataset:

```
data
├── test
│   ├── cam000001.jpg
│   ├── cam000002.jpg
│   ├── cam000003.jpg
│   └── labels.csv
└── train
    ├── cam000207.jpg
    ├── cam000208.jpg
    ├── cam000209.jpg
    └── labels.csv
```

`labels.csv` should have the following structure:

```csv
filename,xmin,ymin,xmax,ymax,width,height,class_text,class_label
cam000001.jpg,4,217,36,291,640,480,pedestrian,1
cam000002.jpg,9,219,52,289,640,480,pedestrian,1
cam000003.jpg,32,217,63,291,640,480,pedestrian,1
```

The TFRecord files can then be generated by running:

```
$ python utils/create_tf_record.py
```

A small example dataset on both formats is provided in `data/sample`.

## Training

```
$ python train.py --help

        USAGE: train.py [flags]
  flags:

  train.py:
    --model_name: <efficient-det-d0|ssd_mobilenet_320>: The model to train. (required)
    --checkpoint_every_n: Number of steps between checkpoints.
    --checkpoint_max_to_keep: Maximum number of checkpoints to keep i.e. n latest.
    --train_steps: Override number of trainig steps.
```

Checkpoints are saved in the `trained` directory.

Additional training config can be specified in the corresponding `pipeline.config` files in the `trained` directory.

Example:

```
# Train a relatively small SSD model.
$ python train.py --model_name ssd_mobilenet_320
```

## Evaluation
Once training is done all saved checkpoints can be evaluated on the validation/test set by running:

```
# Train a relatively small SSD model.
$ python eval.py --model_name trained_model_name
```

## Tensorboard
Training progress and evaluation results can be inspected in tensorboard:

```
$ tensorboard --logdir trained/trained_model_name
```

